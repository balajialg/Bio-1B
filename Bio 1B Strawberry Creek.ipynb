{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bioindicators of Strawberry Creek\n",
    "### Professors George Roderick, John Huelsenbeck & Alan Shabel\n",
    "_Estimated Time: 50 minutes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome! In this lab you will be using data science tools to examine differences in the ecological health between two branches of Strawberry Creek on the Berkeley Campus.\n",
    "\n",
    "**Learning Outcomes**\n",
    "\n",
    "By the end of the notebook, students should be able to:\n",
    "\n",
    "1. Explain the use of biological organisms as indicators of ecosystem health\n",
    "2. Use bootstrapping and permutation test techniques to analyze data\n",
    "3. Interpret biological metrics of diversity: taxon richness, %EPT, biotic index, % filterers, % predators, Shannon index\n",
    "4. Use simulated resampling to determine if two collections of organisms are different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents \n",
    "\n",
    "1. [Jupyter Notebooks](#1)\n",
    "    - [Types of Cells](#1.1)\n",
    "    - [Running Cells](#1.2)\n",
    "    - [Editting, Saving and Submitting](#1.3)\n",
    "    - [Debugging Tips and Jupyter Help](#1.4)\n",
    "<br/><br/>\n",
    "2. [Introduction to Data Analytics](#2)\n",
    "    - [Null and Alternate Hypothesis](#2.1)\n",
    "    - [Permutation Test](#2.2)\n",
    "    - [Bootstrapping](#2.3)\n",
    "<br/><br/>\n",
    "3. [Introduction to Data Analytics](#3)\n",
    "    - [Experiment 1](#3.1)\n",
    "    - [Experiment 2](#3.2)\n",
    "    - [Experiment 3](#3.3)\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebooks <a id='1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab is currently set up in a Jupyter Notebook. A Jupyter Notebook is an online, interactive computing environment, composed of different types of __cells__. Cells are chunks of code or text that are used to break up a larger notebook into smaller, more manageable parts and to let the viewer modify and interact with the elements of the notebook.\n",
    " \n",
    "### Types of cells <a id= '1.1'> </a>\n",
    "\n",
    "There are two types of cells in Jupyter, __code__ cells and __markdown__ cells. Code cells are cells indicated with “In [  ]:” to the left of the cell. In these cells you can write you own code and run the code in the individual cell.\n",
    "Markdown cells hold text a majority of the time and do not have the “In [ ]” to the left of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running cells <a id= '1.2'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Running' a cell is similar to pressing 'Enter' on a calculator once you've typed in an expression; it computes all of the expressions contained within the cell.\n",
    "\n",
    "To run a code cell, you can do one of the following:\n",
    "- press __Shift + Enter__\n",
    "- click __Cell -> Run Cells__ in the toolbar at the top of the screen.\n",
    "\n",
    "You can navigate the cells by either clicking on them or by using your up and down arrow keys. Try running the cell below to see what happens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input of the cell consists of the text/code that is contained within the cell's enclosing box. Here, the input is an expression in Python that \"prints\" or repeats whatever text or number is passed in. \n",
    "\n",
    "The output of running a cell is shown in the line immediately after it. Notice that markdown cells have no output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing, Saving and Sumbitting <a id='1.3'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To __edit__ a cell simply click on the desired cell and begin typing \n",
    "- To __save__ your notebook press _command + s_ on the keyboard \n",
    "- We will go into the specifics of how to __submit__ your work at the end of the lab, but you will essentially be converting your work into a PDF file and then including it in your Lab Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a id='2'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this lab you will be using Python to analyze (the data that you collected from Strawberry Creek/ a condensed data set on the biodiveristy of Strawberry Creek from the last five years). Python is a general-purpose programming language that allows us to use data analysis methods that simulate data sets that we may not have the resources to collect in real life. The main purpose of this lab is to determine whether or not the ecological health of the two branches of the creek are significantly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import qgrid\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Recording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_with individual data sets_ \n",
    "\n",
    "In this section you will be importing the data you collected from your personal experimentation!\n",
    "\n",
    "To import your data you must:\n",
    "1. Open up the desired google sheets form.\n",
    "2. Navigate to the __File__ tab and hover over __Download__.\n",
    "3. From there another drop down tab should appear with differect formats to download the form as. Select the __Comma-Separated Values (csv)__ option.\n",
    "4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_With condensed data set_\n",
    "\n",
    "In this section you will be importing the condensed data set used in the remainder of this lab. \n",
    "\n",
    "To import the data set just run the following cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"data set name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__QGrid__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a Python widget called QGrid to manupulate the data. QGrid allows you to easily filter through the different columns of data in your data set. To implement Qgrid on your data set run the following cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qgrid.show_grid(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To the right of each column title there is a little filter icon that displays a drop down bar when you click on it. From here you can choose which items or numbers you would like to include in you data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Data Analytics <a id= '2'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Hypothesis vs. Alternate Hypothesis <a id='2.1'> </a>\n",
    "\n",
    "One of the first problems to work through when looking at a data set is to determine whether or not the trends in the data are significant or purely due to random chance. In this particular lab we are trying to determine whether or not the difference between the ecological healths of the two branches of the creek are significant or not. To do this we begin by forming a null hypothesis and an alternative hypothesis to test. \n",
    "\n",
    "__Null Hypothesis__: A null hypothesis claims that there is no statistical difference between two distributions and that any difference is due to experimental error or chance.\n",
    "\n",
    "__Alternative Hypothesis__: An alternative hypothesis essentially counters the null hypothesis and claims that the difference in distribution is meaningful, or significant.\n",
    "\n",
    "                        **Maybe we can add a picture here to break up the text?**\n",
    "\n",
    "Example Null and Alternative Hypothesis\n",
    "\n",
    "Say we have a data set with data on the number of boba shops on Southside and Northside. The data set shows that Southside has a higher average of boba shops than Northside, but it is unclear whether the difference in the average is due to chance or some other unknown reason. For this data set, potential hypotheses would be:\n",
    "\n",
    "__Example Null Hypothesis__\n",
    "- The distribution of the average number of boba shops is the same for the samples taken from Southside as the samples taken from Northside. The difference in sample distribution is due to chance. \n",
    "\n",
    "__Example Alternative Hypothesis__  \n",
    "- The average number of boba shops in samples from Southside is lower than the average number of boba shops in samples from Northside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Discussion Questions__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What would be a potential null hypothesis for this lab?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What would be a potential alternative hypothesis?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have your null and alternative hypothesis, the next step is to simulate the distribution under the null hypothesis! Theoretically, if the differences in distributions were solely due to random chance, then the data that the distribution originally comes from would be the same. This is where permutation tests come in to play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Test <a id='2.2'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A permutation test essentially shuffles the given data set and creates new distributions. In this case, we are using a permutation test to shuffle the difference in ecological health of the two creeks. As was previously mentioned, a permutation test simulates the null hypothesis because it assumes that there is no significant difference between the distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate, we will run permutation testing on example data of a biotic index (FBI scores) collected from the North and South Fork. Run the following code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# north_fork_example = pd.DataFrame({\n",
    "#     'FBI Score':[3.5, 4.0, 3.0, 3.5, 4.2],\n",
    "#     'Mean FBI Score':[3.64, 3.64, 3.64, 3.64, 3.64],\n",
    "#     'Score - Mean':[-0.14, 0.36, -0.64, -0.14, 0.56],\n",
    "#     'Square of Difference':[0.0196, 0.1296, 0.4096, 0.0196, 0.3136]\n",
    "# })\n",
    "\n",
    "# north_fork_example\n",
    "\n",
    "example = pd.DataFrame({\n",
    "    'FBI Score':[3.5, 4.0, 3.0, 3.5, 4.2, 4.5, 5.0, 3.6, 4.9, 5.1, 3.4, 2.9],\n",
    "    'Fork':np.append(np.repeat('North', 5), np.repeat('South', 7))\n",
    "})\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example data, we have 5 data points from the North Fork and 7 from the South Fork. Run the cell below to see the observed difference in FBI Score means between the two forks. [note from GR, wondering if we should be using medians?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_difference = example[example['Fork']=='North'].mean() - example[example['Fork']=='South'].mean()\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call this our observed difference because this statistic is observed from data that is actually collected (although generated in our case).\n",
    "\n",
    "In permutation testing, we will be shuffling the data points between the two forks. For one permutation, we will calculate the FBI Score means for each fork. In this case, the mean difference is no longer an observed difference but a simulated difference. Run the cell below to generate a permutation of the data and to calculate the new difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_example = pd.DataFrame({\n",
    "    'FBI Score':example['FBI Score'].sample(len(example['FBI Score'])),\n",
    "    'Fork':np.append(np.repeat('North', 5), np.repeat('South', 7))\n",
    "})\n",
    "perm_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_difference = perm_example[perm_example['Fork']=='North'].mean() - perm_example[perm_example['Fork']=='South'].mean()\n",
    "perm_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just for one permutation of the data. Now we perform the permutation test many more times, and with these values we can plot the distribution of differences. Using this distribution of simulated differences, we can compare it with our actual observed difference to see how likely it is to observe this difference and if our null hypotheis is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_in_means(fbi_scores):\n",
    "    return np.mean(fbi_scores[:5]) - np.mean(fbi_scores[5:])\n",
    "\n",
    "n_repeats = 1000\n",
    "permutation_differences = []\n",
    "for i in range(n_repeats):\n",
    "    permutation = example['FBI Score'].sample(len(example['FBI Score']))\n",
    "    new_difference = difference_in_means(permutation)\n",
    "    permutation_differences.append(new_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(permutation_differences)\n",
    "plt.axvline(observed_difference[0], color='red', label='Observed Difference')\n",
    "plt.xlabel('FBI Score Mean Difference')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this plot, we can guess if the null hypothesis is true (the observed difference between the two branches is due to random chance) or if the alternative hypothesis is true (that it is not due to chance alone)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Discussion Question__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How likely is it for the observed difference to occur, and can we reject the null hypothesis?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Based on the distribution, although it's not very likely to occur, we still can't rule out the possibility of getting the observed difference by random chance, because it is not far enough in the tail of the distribution to be considered as very unlikely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping <a id='2.3'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another problem that often surfaces when analyzing a data set is the accuracy of an estimated statistic. If we wanted to provide an estimate of the average difference in FBI scores between the two forks, the data from your experiment would not be representative of the difference as a whole. On the otherhand, it would also not be feasible to go around collecting samples and calculating the ecological health every single hour. This is where bootstrapping comes into play!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapping generates new random samples by drawing samples from the original data set. We randomly draw from the data set __with replacement__ to create new data sets that are the same size as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will be calculating an estimate for the average difference in FBI Scores. As we previously described, we cannot be sure that the observed_differnce is a good estimate of the difference in FBI Score from this analysis alone. One solution is to use bootstrapping. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the bootstrapping method many times and compile the calculated average FBI differences into one distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FBI_averages = []\n",
    "for i in np.arange(500):\n",
    "    one_new_sample = example.sample(n = 12, replace = True)\n",
    "    average = one_new_sample[one_new_sample['Fork']=='North'].mean() - one_new_sample[one_new_sample['Fork']=='South'].mean()\n",
    "    FBI_averages.append(average)\n",
    "avgs_tbl = pd.DataFrame(FBI_averages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After resampling and calculating the average difference in FBI Scores 100 times, we get this graph that displays the distribution of the average differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs_tbl.hist(\"FBI Score\")\n",
    "plt.hist(observed_difference, color=\"red\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__P-Values & Statistical Significance__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a distribution of what the differences in FBI Scores generally look like, we can calculate the p-value to determine how likely (or probable) it is for the observed_differnce to occur. To calculate the p-value we count the number of times the difference is above or equal to the observed difference in the bootstrapped distribution and divide it by the total amount of bootstrap repetitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_val_count = 0\n",
    "for i in np.arange(500):\n",
    "    in_p_val = avgs_tbl.at[i, \"FBI Score\"] >= observed_difference.at[\"FBI Score\"]\n",
    "    if in_p_val == True:\n",
    "        p_val_count += 1\n",
    "p_val_count / 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the p-value is small, it implies that it is very unlikely for this statistic to occur under the null hypothesis and we say we “reject the null hypothesis”. Otherwise, if the p-value is large, it implies that the observed test statistic has a high likelihood of occurring under the null and we say we “fail to reject the null hypothesis”. \n",
    "\n",
    "A conventional cut-off for p-values is 5%. If the p-value is less than or equal to 5%, then the p-value is deemed “statistically significant”. We will discuss p-values more in lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Discussion Question__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using the calculated p-value above, do we reject the null hypothesis or fail to reject the null hypothesis? Why?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_type answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shannon Index <a id='3.1'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you will learn in class, in addition to taxon richness, the relative abundance of different taxa, termed evenness, is also an important aspect of biological diversity.  One commonly used metric that includes both taxon richness and evenness is the Shannon Diversity Index $(H')$.  This index was originally developed to quantify information content (entropy) in strings of text.  In a string of text with more different letters and more similar relative abundance of letters, it becomes more difficult to predict the next letter in a sequence.  This difficulty is a measure of diversity of letters.  In biology, with more taxa and more similar relative abundance of taxa, it is more difficult to predict the identity of the next taxon in the sample, and thus the sample has higher diversity. As with other metrics, higher diversity is typically associated with better water quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H' = - \\displaystyle\\sum_{i=1}^{R} p_i \\ln{p_i}$$\n",
    "\n",
    "$R$ = number of taxa represented (taxon richness) <br />\n",
    "$p_i$ = proportion of individuals of the $i^{th}$ taxon or species <br />\n",
    "$\\ln$ = natural logarithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In another form, this formula looks like:\n",
    "\n",
    "$$H' = -(p_1 \\ln{p_1} + p_2 \\ln{p_2} + p_3 \\ln{p_3} + \\ldots + p_R \\ln{p_R})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual_counts is a list of integers representing the count of each species\n",
    "# returns the Shannon Diversity Index of individual_counts\n",
    "def calculate_shannon_diversity(individual_counts):\n",
    "    # Normalize proportions to sum to 1\n",
    "    normalized_proportions = np.array(individual_counts) / sum(individual_counts)\n",
    "    # Calculate Shannon Diversity Index\n",
    "    return -1 * sum([p * np.log(p) for p in normalized_proportions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "sample = [60, 10, 25, 1, 4]\n",
    "calculate_shannon_diversity(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting the Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Notebook developed by: Joshua Asuncion, Karalyn Chong, Andy Sheu\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

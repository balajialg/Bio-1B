{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bioindicators of Strawberry Creek\n",
    "### Professors George Roderick, John Huelsenbeck & Alan Shabel\n",
    "_Estimated Time: 50 minutes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome! In this lab you will be using data science tools to examine differences in the ecological health between two branches of Strawberry Creek on the Berkeley Campus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a href=\"https://www.bravoyourcity.com/story/cal-secret-spots-strawberry-creek\"><img src=\\\"images/Bridge.png\\\"></a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Outcomes**\n",
    "\n",
    "By the end of the notebook, students should be able to:\n",
    "\n",
    "1. Explain the use of biological organisms as indicators of ecosystem health\n",
    "2. Interpret biological metrics of diversity: taxon richness, %EPT, biotic index (FBI), % filterers, % predators, Shannon index\n",
    "3. Use simulated resampling, or permutaions, to determine if two distributions are different\n",
    "4. Apply p-value to describe statistical significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents \n",
    "\n",
    "1. [Jupyter Notebooks](#1)\n",
    "    - [Types of Cells](#1.1)\n",
    "    - [Running Cells](#1.2)\n",
    "    - [Editting, Saving and Submitting](#1.3)\n",
    "<br/><br/>\n",
    "2. [Data Recording](#2)\n",
    "<br/><br/>\n",
    "3. [Introduction to Data Analytics](#3)\n",
    "    - [Null and Alternate Hypothesis](#3.1)\n",
    "    - [Permutation Test](#3.2)\n",
    "    - [Bootstrapping, Optional](#3.3)\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebooks <a id='1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab is currently set up in a Jupyter Notebook. A Jupyter Notebook is an online, interactive computing environment, composed of different types of __cells__. Cells are chunks of code or text that are used to break up a larger notebook into smaller, more manageable parts and to let the viewer modify and interact with the elements of the notebook.\n",
    " \n",
    "### Types of cells <a id= '1.1'> </a>\n",
    "\n",
    "There are two types of cells in Jupyter, __code__ cells and __markdown__ cells. Code cells are cells indicated with “In [  ]:” to the left of the cell. In these cells you can write you own code and run the code in the individual cell.\n",
    "Markdown cells hold text a majority of the time and do not have the “In [ ]” to the left of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running cells <a id= '1.2'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Running' a cell is similar to pressing 'Enter' on a calculator once you've typed in an expression; it computes all of the expressions contained within the cell.\n",
    "\n",
    "To run a code cell, you can do one of the following:\n",
    "- press __Shift + Enter__\n",
    "- click __Cell -> Run Cells__ in the toolbar at the top of the screen.\n",
    "\n",
    "You can navigate the cells by either clicking on them or by using your up and down arrow keys. Try running the cell below to see what happens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello, World\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input of the cell consists of the text/code that is contained within the cell's enclosing box. Here, the input is an expression in Python that \"prints\" or repeats whatever text or number is passed in. \n",
    "\n",
    "The output of running a cell is shown in the line immediately after it. Notice that markdown cells have no output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing, Saving and Sumbitting <a id='1.3'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To __edit__ a cell simply click on the desired cell and begin typing \n",
    "- To __save__ your notebook press _command + s_ on the keyboard \n",
    "- We will go into the specifics of how to __submit__ your work at the end of the lab, but you will essentially be converting your work into a PDF file and then including it in your Lab Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a href=\\\"https://en.wikipedia.org/wiki/File:Strawberry_Creek_near_Dwinelle_Hall.jpg\"><img src=\\\"images/Strawberry_Creek.png\\\"></a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this lab you will be using Python to analyze the data that you collected from Strawberry Creek. Python is a general-purpose programming language that allows one to use data analysis methods that simulate data sets that we may not have the resources to collect in real life. \n",
    "\n",
    "The main purpose of this lab is to use biological metrics to determine whether or not the ecological health of the two branches of the creek is significantly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-d66ce36bba35>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-d66ce36bba35>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install qgrid\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install qgrid\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import qgrid\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Recording <a id='2'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will be importing the data you collected in the lab!\n",
    "\n",
    "To import your data you must:\n",
    "1. Open up the desired google sheets form.\n",
    "2. Navigate to the __File__ tab and hover over __Download__.\n",
    "3. From there another drop down tab should appear with differect formats to download the form as. Select the __Comma-Separated Values (csv)__ option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import the data set just run the following cell!  If all goes smoothly, you will see the first few rows of your data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Fork</th>\n",
       "      <th>Richness</th>\n",
       "      <th>EPT</th>\n",
       "      <th>FBI</th>\n",
       "      <th>Filters</th>\n",
       "      <th>Predators</th>\n",
       "      <th>Shannon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>North</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>5.52</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>North</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>5.14</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>North</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>5.28</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>North</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>5.48</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>North</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>5.18</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group   Fork  Richness  EPT   FBI  Filters  Predators  Shannon\n",
       "0      1  North         8   32  5.52       36          6      0.9\n",
       "1      2  North         7   42  5.14       36          6      0.9\n",
       "2      3  North         7   40  5.28       62          2      0.4\n",
       "3      4  North         6   50  5.48       65          0      0.5\n",
       "4      5  North         6   30  5.18       66          0      1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_csv(\"data set name\")\n",
    "data = pd.read_csv(\"SC_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__QGrid__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a Python widget called QGrid to manupulate the data. QGrid allows you to easily filter through and examine the different columns of data in your data set. To implement Qgrid on your data set run the following cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qgrid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1028e0483ae6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#data.describe()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qgrid' is not defined"
     ]
    }
   ],
   "source": [
    "qgrid.show_grid(data)\n",
    "#data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To the right of each column title there is a little filter icon that displays a drop down bar when you click on it. From here you can choose which items or numbers you would like to include in you data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Data Analytics <a id= '3'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Hypothesis vs. Alternate Hypothesis <a id='3.1'> </a>\n",
    "\n",
    "One of the first problems to work through when looking at a data set is to determine whether or not the trends in the data are significant or purely due to random chance. In this particular lab we are trying to determine whether or not the difference between the ecological healths of the two branches of the creek are significant or not. To do this we begin by forming a null hypothesis and an alternative hypothesis to test. \n",
    "\n",
    "__Null Hypothesis__: A null hypothesis claims that there is no statistical difference between two distributions and that any difference is due to experimental error or chance.\n",
    "\n",
    "__Alternative Hypothesis__: An alternative hypothesis essentially counters the null hypothesis and claims that the difference in distribution is meaningful, or significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Null and Alternative Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a href=\"https://www.google.com/maps/d/u/0/viewer?mid=1yOYDwS7P2bIUFqUmzW_QZdg-6uWoO7Jv&ll=37.87133135974079%2C-122.26288979999998&z=16\"><img src=\\\"images/Map.png\\\"></a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Say we have a data set with data on the number of boba shops on Southside and Northside. The data set shows that Southside has a higher average of boba shops than Northside, but it is unclear whether the difference in the average is due to chance or some other unknown reason. For this data set, potential hypotheses would be:\n",
    "\n",
    "__Example Null Hypothesis__\n",
    "- The distribution of the average number of boba shops is the same for the samples taken from Southside as the samples taken from Northside. The difference in sample distribution is due to chance. \n",
    "\n",
    "__Example Alternative Hypothesis__  \n",
    "- The average number of boba shops in samples from Southside is lower than the average number of boba shops in samples from Northside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Discussion Questions__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What would be a potential null hypothesis for this lab?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What would be a potential alternative hypothesis?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have your null and alternative hypothesis, the next step is to simulate the distribution under the null hypothesis! Theoretically, if the differences in distributions were solely due to random chance, then the data that the distribution originally comes from would be the same. This is where permutation tests come in to play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Test <a id='3.2'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A permutation test essentially shuffles the given data set among categories and creates new distributions. In this case, we are using a permutation test to shuffle the difference in ecological health of the two creeks. As was previously mentioned, a permutation test simulates the null hypothesis because it assumes that there is no significant difference between the distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate, we will run permutation testing on example data of a biotic index (FBI scores) collected from the North and South Fork. These are example data to understand the process.  You will analyze your own data after this.\n",
    "\n",
    "Run the following code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example = pd.DataFrame({\n",
    "    'FBI Score':[3.5, 4.0, 3.0, 3.5, 4.2, 4.5, 5.0, 3.6, 4.9, 5.1, 3.4, 2.9],\n",
    "    'Fork':np.append(np.repeat('North', 5), np.repeat('South', 7))\n",
    "})\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to see the observed difference in FBI means between the two samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_difference = example[example['Fork']=='North'].mean() - example[example['Fork']=='South'].mean()\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call this our observed difference because this statistic is observed from data that is actually collected, although from an example in our case.\n",
    "\n",
    "In permutation testing, we will be shuffling the data points between the two forks. For one permutation, we will calculate the FBI Score means for each fork. In this case, the mean difference is no longer an observed difference but a simulated difference. Run the cells below to generate a permutation of the data and to calculate the new difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_example = pd.DataFrame({\n",
    "    'FBI Score':example['FBI Score'].sample(len(example['FBI Score'])),\n",
    "    'Fork':np.append(np.repeat('North', 5), np.repeat('South', 7))\n",
    "})\n",
    "perm_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_difference = perm_example[perm_example['Fork']=='North'].mean() - perm_example[perm_example['Fork']=='South'].mean()\n",
    "perm_difference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just for one permutation of the data. Now we perform the permutation test many more times, and with these values we can plot the distribution of differences. Using this distribution of simulated differences, we can compare it with our actual observed difference to see how likely it is to observe this difference and if our null hypotheis is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_in_means(fbi_scores):\n",
    "    return np.mean(fbi_scores[:5]) - np.mean(fbi_scores[5:])\n",
    "\n",
    "n_repeats = 1000\n",
    "permutation_differences = []\n",
    "for i in range(n_repeats):\n",
    "    permutation = example['FBI Score'].sample(len(example['FBI Score']))\n",
    "    new_difference = difference_in_means(permutation)\n",
    "    permutation_differences.append(new_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(permutation_differences)\n",
    "plt.axvline(observed_difference[0], color='red', label='Observed Difference')\n",
    "plt.xlabel('FBI Score Mean Difference')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this plot, we can guess if the null hypothesis is true (the observed difference between the two branches is due to random chance) or if the alternative hypothesis is true (that it is not due to chance alone)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Discussion Question__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How likely is it for the observed difference to occur, and can we reject the null hypothesis?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Based on the distribution, although it's not very likely to occur, we still can't rule out the possibility of getting the observed difference by random chance, because it is not far enough in the tail of the distribution to be considered as very unlikely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__P-Values & Statistical Significance__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a distribution of what the differences in FBI Scores generally look like, we can calculate the p-value to determine how probable it is for the observed_differnce to occur. To calculate the p-value we count the number of times the difference is more extreme or equal to the observed difference in the bootstrapped distribution and divide it by the total amount of bootstrap repetitions. Note that for some hypotheses the observed value may be on the left side of the distribution and for others, the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_val_count = sum(i <= observed_difference[0]for i in permutation_differences)/len(permutation_differences)\n",
    "p_val_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the p-value is small, it implies that it is very unlikely for this statistic to occur under the null hypothesis and we say we “reject the null hypothesis”. Otherwise, if the p-value is large, it implies that the observed test statistic has a high likelihood of occurring under the null and we say we “fail to reject the null hypothesis”. \n",
    "\n",
    "A conventional cut-off for p-values is 0.05 or 5%. If the p-value is less than or equal to 5%, then the p-value is deemed “statistically significant”. Here, the p-value is larger than that. We will discuss p-values more in lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Discussion Question__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using the calculated p-value above, do we reject the null hypothesis or fail to reject the null hypothesis? Why?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_type answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your data<a id='4'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will calculate the mean differences for each of the metrics you measured.  Run the next cell for the observerd differences between forks for each of the biological measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_difference = data[data['Fork']=='North'].mean() - data[data['Fork']=='South'].mean()\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the FBI index.  The next cell runs the permutations, graphs the data, and calculates a p-value, just like for the sample data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_in_means(SC_scores):\n",
    "    return np.mean(SC_scores[:10]) - np.mean(SC_scores[10:])\n",
    "\n",
    "n_repeats = 1000\n",
    "permutation_differences = []\n",
    "for i in range(n_repeats):\n",
    "    permutation = data['FBI'].sample(len(data['FBI']))\n",
    "    new_difference = difference_in_means(permutation)\n",
    "    permutation_differences.append(new_difference)\n",
    "    \n",
    "plt.hist(permutation_differences)\n",
    "plt.axvline(observed_difference[\"FBI\"], color='red', label='Observed Difference')\n",
    "plt.xlabel('FBI Mean Difference')\n",
    "plt.legend();\n",
    "\n",
    "p_val_count = sum(i >= observed_difference[\"FBI\"] for i in permutation_differences)/len(permutation_differences)\n",
    "p_val_count\n",
    "    \n",
    "#permutation_differences\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is easy to do repeat the same analysis for each of the other biological measures.  Note, that for the p-value, if the observed difference is on the _left_ side of the distribution, you are interested in how many permutations were more extreme on the _left_ side.  In the code, we will have to change the <= sign in the line i >= observed_difference[\"measure\"] to i <= observed_difference[\"measure\"].  We have tried to make these edits for you already.\n",
    "\n",
    "One of the values of using a Notebook, is that it makes repeating the same process easy and repeatable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_in_means(SC_scores):\n",
    "    return np.mean(SC_scores[:10]) - np.mean(SC_scores[10:])\n",
    "\n",
    "n_repeats = 1000\n",
    "permutation_differences = []\n",
    "for i in range(n_repeats):\n",
    "    permutation = data['Richness'].sample(len(data['Richness']))\n",
    "    new_difference = difference_in_means(permutation)\n",
    "    permutation_differences.append(new_difference)\n",
    "    \n",
    "plt.hist(permutation_differences)\n",
    "plt.axvline(observed_difference[\"Richness\"], color='red', label='Observed Difference')\n",
    "plt.xlabel('Richness Mean Difference')\n",
    "plt.legend();\n",
    "\n",
    "p_val_count = sum(i <= observed_difference[\"Richness\"] for i in permutation_differences)/len(permutation_differences)\n",
    "p_val_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_in_means(SC_scores):\n",
    "    return np.mean(SC_scores[:10]) - np.mean(SC_scores[10:])\n",
    "\n",
    "n_repeats = 1000\n",
    "permutation_differences = []\n",
    "for i in range(n_repeats):\n",
    "    permutation = data['EPT'].sample(len(data['EPT']))\n",
    "    new_difference = difference_in_means(permutation)\n",
    "    permutation_differences.append(new_difference)\n",
    "    \n",
    "plt.hist(permutation_differences)\n",
    "plt.axvline(observed_difference[\"EPT\"], color='red', label='Observed Difference')\n",
    "plt.xlabel('EPT Mean Difference')\n",
    "plt.legend();\n",
    "\n",
    "p_val_count = sum(i <= observed_difference[\"EPT\"] for i in permutation_differences)/len(permutation_differences)\n",
    "p_val_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_in_means(SC_scores):\n",
    "    return np.mean(SC_scores[:10]) - np.mean(SC_scores[10:])\n",
    "\n",
    "n_repeats = 1000\n",
    "permutation_differences = []\n",
    "for i in range(n_repeats):\n",
    "    permutation = data['Filters'].sample(len(data['Filters']))\n",
    "    new_difference = difference_in_means(permutation)\n",
    "    permutation_differences.append(new_difference)\n",
    "    \n",
    "plt.hist(permutation_differences)\n",
    "plt.axvline(observed_difference[\"Filters\"], color='red', label='Observed Difference')\n",
    "plt.xlabel('Filters Mean Difference')\n",
    "plt.legend();\n",
    "\n",
    "p_val_count = sum(i >= observed_difference[\"Filters\"] for i in permutation_differences)/len(permutation_differences)\n",
    "p_val_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_in_means(SC_scores):\n",
    "    return np.mean(SC_scores[:10]) - np.mean(SC_scores[10:])\n",
    "\n",
    "n_repeats = 1000\n",
    "permutation_differences = []\n",
    "for i in range(n_repeats):\n",
    "    permutation = data['Predators'].sample(len(data['Predators']))\n",
    "    new_difference = difference_in_means(permutation)\n",
    "    permutation_differences.append(new_difference)\n",
    "    \n",
    "plt.hist(permutation_differences)\n",
    "plt.axvline(observed_difference[\"Predators\"], color='red', label='Observed Difference')\n",
    "plt.xlabel('Predators Mean Difference')\n",
    "plt.legend();\n",
    "\n",
    "p_val_count = sum(i <= observed_difference[\"Predators\"] for i in permutation_differences)/len(permutation_differences)\n",
    "p_val_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_in_means(SC_scores):\n",
    "    return np.mean(SC_scores[:10]) - np.mean(SC_scores[10:])\n",
    "\n",
    "n_repeats = 1000\n",
    "permutation_differences = []\n",
    "for i in range(n_repeats):\n",
    "    permutation = data['Shannon'].sample(len(data['Shannon']))\n",
    "    new_difference = difference_in_means(permutation)\n",
    "    permutation_differences.append(new_difference)\n",
    "    \n",
    "plt.hist(permutation_differences)\n",
    "plt.axvline(observed_difference[\"Shannon\"], color='red', label='Observed Difference')\n",
    "plt.xlabel('Shannon Mean Difference')\n",
    "plt.legend();\n",
    "\n",
    "p_val_count = sum(i <= observed_difference[\"Shannon\"] for i in permutation_differences)/len(permutation_differences)\n",
    "p_val_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting the Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Notebook developed by: Joshua Asuncion, Karalyn Chong, Andy Sheu\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
